import OpenAI from 'openai';
import { getSystemPrompt } from './system_instructions';

const OPENAI_VECTOR_STORE_ID = process.env.OPENAI_VECTOR_STORE_ID;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

interface GenerateStreamResponseParams {
    userMessage: string;
    model: string;
    previousResponseId?: string | null;
    roomId?: string;
    approved?: boolean;
    currentLocation?: string;
}

export async function* generateStreamResponse({
    userMessage,
    model,
    previousResponseId,
    roomId,
    approved,
    currentLocation
}: GenerateStreamResponseParams): AsyncGenerator<any, void, unknown> {
    try {
        // システムプロンプトを動的生成
        const systemPrompt = getSystemPrompt(
            roomId || '', 
            approved || false, 
            currentLocation ? currentLocation : undefined
        );
        console.info("Generated system prompt for:", { roomId, approved, currentLocation });

        let tools: any[] = [];

        // File Search ツール
        if (OPENAI_VECTOR_STORE_ID) {
            const fileSearchTool: any = {
                type: "file_search",
                vector_store_ids: [OPENAI_VECTOR_STORE_ID],
                max_num_results: 10,
                ranking_options: { score_threshold: 0.2 }
            };
            tools.push(fileSearchTool);
        }

        // Web Search ツール
        const webSearchTool: any = {
            type: "web_search_preview"
        };
        tools.push(webSearchTool);

        console.info("Enabled tools:", tools.map(t => t.type));

        const requestPayload: any = {
            model: model,
            instructions: systemPrompt,
            input: [{ role: "user", content: userMessage }],
            tools: tools,
            temperature: 0.0,
            truncation: "auto",
            stream: true,
            text: {
                format: {
                    type: "json_schema",
                    name: "assistant_response",
                    schema: {
                        type: "object",
                        properties: {
                            assistant_response_text: {
                                type: "string",
                                description: "The final text response generated by the assistant based on the file search results or lack thereof."
                            },
                            reference_files: {
                                type: "array",
                                items: { type: "string" },
                                description: "If the assistant referenced the database (file search), this is a list of referenced file names. Otherwise, it will be an empty array."
                            },
                            images: {
                                type: "array",
                                items: { type: "string" },
                                description: "An array of absolute HTTPS image URLs relevant to the answer for display in the chat UI. If none are relevant, return an empty array []. Limit to at most 15."
                            }
                        },
                        required: ["assistant_response_text", "reference_files", "images"],
                        additionalProperties: false
                    }
                }
            }
        };
        if (previousResponseId) requestPayload.previous_response_id = previousResponseId;

        const response = await openai.responses.create(requestPayload);

        for await (const chunk of response as unknown as AsyncIterable<any>) {
            yield chunk;
        }

        yield `data: ${JSON.stringify({ completed: true })}\n\n`;

        console.info("Response API stream completed successfully");
    } catch (e) {
        console.error(`Error in generateStreamResponse: ${e}`);
        yield `data: ${JSON.stringify({ error: String(e) })}\n\n`;
    }
}