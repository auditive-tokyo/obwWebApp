import openai
import json

async def openai_vector_search_with_file_search_tool( # 関数名をより具体的に
    openai_async_client: openai.AsyncOpenAI,
    query_text: str,
    language: str,
    vector_store_id: str = None # 特定のベクトルストアIDを渡せるようにする
) -> str:
    if not openai_async_client:
        print("Error: OpenAI async client not provided.")
        return "エラー: OpenAIクライアントが利用できません。"
    
    if not vector_store_id:
        print("Error: Vector Store ID not provided or configured.")
        return "エラー: 検索対象のデータベースが設定されていません。"

    print(f"File Search Tool を使用して検索開始: '{query_text}' (Vector Store: {vector_store_id})")

    system_instructions = f"""あなたはOsaka Bay Wheelというホテルの親切な電話応答アシスタントです。
ユーザーからの質問に対して、提供された File Search ツールを使って関連情報を検索し、その情報に基づいて {language} で自然な応答を生成してください。
電話でPollyが話しやすいように、簡潔でSpeech Synthesisに適したテキストを生成してください。

検索結果が見つからない場合や、情報が不十分な場合は、その旨を正確に伝え、オペレーターと話す必要があるか確認してください。

File Search ツールが情報を引用した場合 (annotations が空でない場合) は 'information_found_in_db' を true に、引用しなかった場合は false に設定してください。
応答テキストは 'assistant_response_text' に含めてください。
"""
    try:
        response_format_schema = {
            "type": "object",
            "properties": {
                "assistant_response_text": {
                    "type": "string",
                    "description": "The final text response generated by the assistant based on the file search results or lack thereof."
                },
                "information_found_in_db": {
                    "type": "boolean",
                    "description": "True if relevant information was found and cited from the database (file search), false otherwise."
                }
            },
            "required": ["assistant_response_text", "information_found_in_db"],
            "additionalProperties": False
        }
        response = await openai_async_client.responses.create(
            model="gpt-4.1-mini",
            instructions=system_instructions,
            input=[
                {"role": "user", "content": query_text}
            ],
            tools=[
                {
                    "type": "file_search",
                    "vector_store_ids": [vector_store_id],
                    "max_num_results": 10,
                    "ranking_options": {
                        "score_threshold": 0.2
                    },
                    "filters": { # TODO: ここは動的にvalueを設定すること
                        "key": "room_number",
                        "type": "eq",
                        "value": "201"
                    }
                }
            ],
            tool_choice="required",
            temperature=0.5,
            text={
                "format": {
                    "type": "json_schema",
                    "name": "AssistantResponse",
                    "schema": response_format_schema,
                    "strict": True
                }
            }
        )

        # --- API呼び出し成功時のレスポンス全体を出力 ---
        print("--- OpenAI API Response (Success with JSON Schema) ---")
        print(response) # デバッグが完了したらコメントアウトしても良い
        print(f"Response object type: {type(response)}")
        if hasattr(response, 'output'):
            print(f"Response output type: {type(response.output)}")
        print("--- End of OpenAI API Response ---")

        generated_text = "検索結果に基づく応答の抽出に失敗しました。" # デフォルト

        if response and hasattr(response, 'output'):
            # json_schema を指定した場合、output はリストで、
            # その中の ResponseOutputMessage -> content -> ResponseOutputText.text にJSON文字列が含まれると期待
            if isinstance(response.output, list) and len(response.output) > 0: # 通常は > 1 だが、ツールコールがない場合も考慮
                # ResponseOutputMessage を探す (通常はリストの最後の方、または type で判断)
                # ここでは、File Search Tool がある前提で2番目 (index 1) を試す
                # より堅牢にするなら、リストをループして type == 'message' を探す
                output_message_item = None
                if len(response.output) > 1 and hasattr(response.output[1], 'type') and response.output[1].type == 'message':
                    output_message_item = response.output[1]
                else: # 見つからない場合、リストの最後の要素がメッセージかもしれないと仮定 (またはループで探す)
                    for item in reversed(response.output):
                        if hasattr(item, 'type') and item.type == 'message':
                            output_message_item = item
                            break
                
                if output_message_item:
                    if hasattr(output_message_item, 'content') and isinstance(output_message_item.content, list) and len(output_message_item.content) > 0:
                        output_text_obj = output_message_item.content[0]
                        if hasattr(output_text_obj, 'type') and output_text_obj.type == 'output_text':
                            if hasattr(output_text_obj, 'text') and isinstance(output_text_obj.text, str):
                                try:
                                    output_json = json.loads(output_text_obj.text)
                                    generated_text = output_json.get("assistant_response_text", "Error: 'assistant_response_text' key missing in JSON.")
                                except json.JSONDecodeError:
                                    print(f"Error: Failed to parse JSON from output_text_obj.text: {output_text_obj.text}")
                                    generated_text = "Error: Invalid JSON in text attribute."
                            else:
                                print("Error: ResponseOutputText.text is missing or not a string.")
                        else:
                             print(f"Error: Expected ResponseOutputText, but got {type(output_text_obj)}.")
                    else:
                        print("Error: ResponseOutputMessage 'content' is not a list or is empty.")
                else:
                    print("Error: Could not find ResponseOutputMessage in response.output.")

            # フォールバック: もし output が直接JSON文字列や辞書だった場合 (json_schema の理想的な挙動)
            elif isinstance(response.output, str):
                try:
                    output_json = json.loads(response.output)
                    generated_text = output_json.get("assistant_response_text", "Error: 'assistant_response_text' key missing in JSON.")
                except json.JSONDecodeError:
                    print(f"Error: Failed to parse JSON from response.output: {response.output}")
                    generated_text = "Error: Invalid JSON response from API."
            elif isinstance(response.output, dict):
                generated_text = response.output.get("assistant_response_text", "Error: 'assistant_response_text' key missing in dict.")
            else:
                print(f"Error: response.output is an unexpected type: {type(response.output)}")
        else:
            print("Error: Response object or response.output is missing.")

        print(f"File Search Tool による応答生成完了。抽出結果: {generated_text}")
        return generated_text

    except openai.APIConnectionError as e:
        print(f"OpenAI APIへの接続エラー: {e}")
        return "申し訳ありません、現在データベースへの接続に問題が発生しています。"
    except openai.RateLimitError as e:
        print(f"OpenAI APIレート制限エラー: {e}")
        return "現在、多くのお問い合わせを処理中です。恐れ入りますが、少し時間をおいて再度お試しください。"
    except openai.APIStatusError as e:
        error_details_str = "N/A"
        try:
            # e.response.json() を試みる
            error_details_json = e.response.json()
            error_details_str = json.dumps(error_details_json, indent=2, ensure_ascii=False)
        except json.JSONDecodeError:
            # JSONデコードに失敗したらテキストとして取得
            error_details_str = e.response.text
        except Exception as ex_detail:
            error_details_str = f"エラー詳細の取得中に別のエラーが発生: {ex_detail}"

        print(f"OpenAI APIステータスエラー (HTTP {e.status_code}): {e.response}")
        print(f"エラー詳細:\n{error_details_str}") # ★エラー詳細を確実に出力
        return "データベース検索中に予期せぬエラーが発生しました。管理者にご連絡ください。" # エラー時はここで処理を終える
    except Exception as e:
        print(f"File Search Tool 処理中に予期せぬエラーが発生しました: {e}")
        return f"「{query_text}」の検索中にエラーが発生しました。"

# # --- テスト実行用のコード ---
# if __name__ == "__main__":
#     import asyncio
#     import os
#     from dotenv import load_dotenv

#     load_dotenv()

#     async def main_file_search_test():
#         api_key = os.environ.get("OPENAI_API_KEY")
#         if not api_key:
#             print("テスト実行エラー: 環境変数 OPENAI_API_KEY が設定されていません。")
#             return
        
#         # テスト用のベクトルストアID (環境変数から取得するか、ハードコード)
#         test_vector_store_id = os.environ.get("TEST_VECTOR_STORE_ID", "") # ★ ここで読み込んでいます
#         if not test_vector_store_id: # 値が空文字の場合もチェック
#              print(f"警告: テスト用のベクトルストアID (TEST_VECTOR_STORE_ID) が設定されていません。")
#              # return # テストを続行しない場合はコメント解除

#         openai_async_client = openai.AsyncOpenAI(api_key=api_key)

#         print("\n--- File Search Tool (Responses APIスタイル) テスト開始 ---")
#         # ... (test_queries の定義) ...
#         test_queries = {
#             "部屋のキーの場所": "部屋のキーはどこですか？",
#             # "プールの情報": "プールは使えますか？",
#             # "ホテルまでの道のり": "ホテルまでの行き方を教えてください。",
#         }
#         for description, query in test_queries.items():
#             print(f"\nテストクエリ ({description}): 「{query}」")
#             # 現在の openai_vector_search_with_file_search_tool 関数は
#             # 内部で filters をハードコードしているため、そのまま呼び出します。
#             result = await openai_vector_search_with_file_search_tool(
#                 openai_async_client,
#                 query,
#                 "日本語",
#                 test_vector_store_id # ★ 読み込んだ test_vector_store_id を使用
#             )
#             print(f"検索結果/応答: {result}")
        
#         print("\n--- File Search Tool テスト終了 ---")
#         await openai_async_client.close()

#     asyncio.run(main_file_search_test())