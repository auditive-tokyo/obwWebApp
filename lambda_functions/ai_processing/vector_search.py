import openai
import json

async def openai_vector_search_with_file_search_tool(
    openai_async_client: openai.AsyncOpenAI,
    query_text: str,
    language: str,
    vector_store_id: str = None
) -> str:
    if not openai_async_client:
        print("Error: OpenAI async client not provided.")
        return json.dumps({"assistant_response_text": "エラー: OpenAIクライアントが利用できません。", "information_found_in_db": False}) # ★ エラー時もスキーマに合わせる
    
    if not vector_store_id:
        print("Error: Vector Store ID not provided or configured.")
        return json.dumps({"assistant_response_text": "エラー: 検索対象のデータベースが設定されていません。", "information_found_in_db": False}) # ★ エラー時もスキーマに合わせる

    print(f"File Search Tool を使用して検索開始: '{query_text}' (Vector Store: {vector_store_id})")

    system_instructions = f"""あなたはOsaka Bay Wheelというホテルの親切な電話アシスタントです。
ユーザーからの質問に対して、提供された File Search ツールを使って関連情報を検索し、その情報に基づいて {language} で自然な応答を生成してください。
電話でPollyが話しやすいように、簡潔でSpeech Synthesisに適した文を心がけてください。

検索結果が見つからない場合や、情報が不十分な場合は、その旨を正確に伝え、オペレーターと話す必要があるか確認してください。

File Search ツールが情報を引用した場合 (annotations が空でない場合) は 'information_found_in_db' を true に、引用しなかった場合は false に設定してください。
応答テキストは 'assistant_response_text' に含めてください。
"""
    try:
        response_format_schema = {
            "type": "object",
            "properties": {
                "assistant_response_text": {
                    "type": "string",
                    "description": "The final text response generated by the assistant based on the file search results or lack thereof."
                },
                "information_found_in_db": { # ★ 新しいプロパティを追加
                    "type": "boolean",
                    "description": "True if relevant information was found and cited from the database (file search), false otherwise."
                }
            },
            "required": ["assistant_response_text", "information_found_in_db"], # ★ required に追加
            "additionalProperties": False
        }
        response = await openai_async_client.responses.create(
            model="gpt-4.1-mini",
            instructions=system_instructions,
            input=[
                {"role": "user", "content": query_text}
            ],
            tools=[
                {
                    "type": "file_search",
                    "vector_store_ids": [vector_store_id],
                    "max_num_results": 10,
                    "ranking_options": {
                        "score_threshold": 0.2
                    },
                    "filters": { # TODO: このフィルターはテスト用です。実際には動的に設定する必要があります。
                        "key": "room_number",
                        "type": "eq",
                        "value": "201"
                    }
                }
            ],
            tool_choice="required",
            temperature=0.5,
            text={
                "format": {
                    "type": "json_schema",
                    "name": "AssistantResponse",
                    "schema": response_format_schema,
                    "strict": True
                }
            }
        )

        print("--- OpenAI API Response (Success with JSON Schema) ---")
        # print(response) # デバッグ用にレスポンス全体を出力
        
        # レスポンスの構造をより詳細に出力して確認
        generated_json_text = "{\"assistant_response_text\": \"検索結果に基づく応答の抽出に失敗しました。\", \"information_found_in_db\": false}" # デフォルト

        if response and hasattr(response, 'output'):
            if isinstance(response.output, list) and len(response.output) > 0:
                output_message_item = None
                # 最後の 'message' タイプの出力を探す
                for item in reversed(response.output):
                    if hasattr(item, 'type') and item.type == 'message':
                        output_message_item = item
                        break
                
                if output_message_item and hasattr(output_message_item, 'content') and \
                   isinstance(output_message_item.content, list) and len(output_message_item.content) > 0:
                    
                    output_text_obj = output_message_item.content[0]
                    if hasattr(output_text_obj, 'type') and output_text_obj.type == 'output_text' and \
                       hasattr(output_text_obj, 'text') and isinstance(output_text_obj.text, str):
                        
                        generated_json_text = output_text_obj.text
                        # ここでモデルがスキーマ通りにJSONを生成したか確認
                        print(f"Model generated JSON string: {generated_json_text}")
                        try:
                            # 念のためパースして必須キーがあるか確認 (ただし、この関数の返り値は文字列のまま)
                            parsed_output = json.loads(generated_json_text)
                            if "assistant_response_text" not in parsed_output or \
                               "information_found_in_db" not in parsed_output:
                                print("Warning: Model output JSON is missing required keys.")
                                # 不足している場合はデフォルト値で補完したJSON文字列を再構築することも検討できる
                        except json.JSONDecodeError:
                            print(f"Error: Failed to parse JSON from model output: {generated_json_text}")
                            # エラー時はデフォルトのJSON文字列を使用
                    else:
                        print(f"Error: Expected ResponseOutputText with text string, but got: {output_text_obj}")
                else:
                    print("Error: Could not find valid ResponseOutputMessage content.")
            else:
                print(f"Error: response.output is not a list or is empty: {response.output}")
        else:
            print("Error: Response object or response.output is missing.")

        print(f"File Search Tool による応答生成完了。抽出されたJSON文字列: {generated_json_text}")
        return generated_json_text # ★ JSON文字列をそのまま返す

    except openai.APIConnectionError as e:
        print(f"OpenAI APIへの接続エラー: {e}")
        return json.dumps({"assistant_response_text": "申し訳ありません、現在データベースへの接続に問題が発生しています。", "information_found_in_db": False})
    except openai.RateLimitError as e:
        print(f"OpenAI APIレート制限エラー: {e}")
        return json.dumps({"assistant_response_text": "現在、多くのお問い合わせを処理中です。恐れ入りますが、少し時間をおいて再度お試しください。", "information_found_in_db": False})
    except openai.APIStatusError as e:
        error_details_str = "N/A"
        try:
            error_details_json = e.response.json()
            error_details_str = json.dumps(error_details_json, indent=2, ensure_ascii=False)
        except json.JSONDecodeError:
            error_details_str = e.response.text
        except Exception as ex_detail:
            error_details_str = f"エラー詳細の取得中に別のエラーが発生: {ex_detail}"
        print(f"OpenAI APIステータスエラー (HTTP {e.status_code}): {e.response}")
        print(f"エラー詳細:\n{error_details_str}")
        return json.dumps({"assistant_response_text": "データベース検索中に予期せぬエラーが発生しました。管理者にご連絡ください。", "information_found_in_db": False})
    except Exception as e:
        print(f"File Search Tool 処理中に予期せぬエラーが発生しました: {e}")
        return json.dumps({"assistant_response_text": f"「{query_text}」の検索中にエラーが発生しました。", "information_found_in_db": False})

# --- テスト実行用のコード ---
if __name__ == "__main__":
    import asyncio
    import os
    from dotenv import load_dotenv

    load_dotenv()

    async def main_file_search_test():
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key:
            print("テスト実行エラー: 環境変数 OPENAI_API_KEY が設定されていません。")
            return
        
        # テスト用のベクトルストアID (環境変数から取得するか、ハードコード)
        test_vector_store_id = os.environ.get("TEST_VECTOR_STORE_ID", "") # ★ ここで読み込んでいます
        if not test_vector_store_id: # 値が空文字の場合もチェック
             print(f"警告: テスト用のベクトルストアID (TEST_VECTOR_STORE_ID) が設定されていません。")
             # return # テストを続行しない場合はコメント解除

        openai_async_client = openai.AsyncOpenAI(api_key=api_key)

        print("\n--- File Search Tool (Responses APIスタイル) テスト開始 ---")
        # ... (test_queries の定義) ...
        test_queries = {
            "部屋のキーの場所": "部屋のキーはどこですか？",
            # "プールの情報": "プールは使えますか？",
            # "ホテルまでの道のり": "ホテルまでの行き方を教えてください。",
        }
        for description, query in test_queries.items():
            print(f"\nテストクエリ ({description}): 「{query}」")
            # 現在の openai_vector_search_with_file_search_tool 関数は
            # 内部で filters をハードコードしているため、そのまま呼び出します。
            result = await openai_vector_search_with_file_search_tool(
                openai_async_client,
                query,
                "日本語",
                test_vector_store_id # ★ 読み込んだ test_vector_store_id を使用
            )
            print(f"検索結果/応答: {result}")
        
        print("\n--- File Search Tool テスト終了 ---")
        await openai_async_client.close()

    asyncio.run(main_file_search_test())