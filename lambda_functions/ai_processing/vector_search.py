import openai
import json

async def openai_vector_search_with_file_search_tool(
    openai_async_client: openai.AsyncOpenAI,
    query_text: str,
    language: str,
    vector_store_id: str = None,
    previous_response_id: str = None # 将来的に使用
) -> str: # 返り値はJSON文字列の想定に戻す
    
    print(f"Previous Response ID: {previous_response_id}") # デバッグ用

    if not openai_async_client:
        print("Error: OpenAI async client not provided.")
        # "retrieved_annotations" を削除
        return json.dumps({"assistant_response_text": "エラー: OpenAIクライアントが利用できません。", "needs_operator": False, "response_id": None}, ensure_ascii=False)
    
    if not vector_store_id:
        print("Error: Vector Store ID not provided or configured.")
        # "retrieved_annotations" を削除
        return json.dumps({"assistant_response_text": "エラー: 検索対象のデータベースが設定されていません。", "needs_operator": False, "response_id": None}, ensure_ascii=False)

    print(f"File Search Tool を使用して検索開始: '{query_text}' (Vector Store: {vector_store_id})")

    system_instructions = f"""あなたはOsaka Bay Wheelというホテルの親切な電話応答アシスタントです。
ユーザーからの質問に対して、提供された File Search ツールを使って関連情報を検索し、その情報に基づいて {language} で自然な応答を生成してください。
電話でPollyが話しやすいように、簡潔でSpeech Synthesisに適したテキストを生成してください。

検索結果が見つからない場合や、情報が不十分な場合は、その旨を正確に伝え、オペレーターと話す必要があるか確認してください。
オペレーターと話す必要があるか確認をした場合、'needs_operator' フラグをTrueにしてください。それ以外は全てFalseにしてください。

応答テキストは 'assistant_response_text' に含めてください。
"""
    try:
        response_format_schema = {
            "type": "object",
            "properties": {
                "assistant_response_text": {
                    "type": "string",
                    "description": "The final text response generated by the assistant based on the file search results or lack thereof."
                },
                "needs_operator": {
                    "type": "boolean",
                    "description": "True if the user explicitly states a need to speak with an operator, false otherwise. Defaults to false in this initial search phase."
                }
            },
            "required": ["assistant_response_text", "needs_operator"],
            "additionalProperties": False
        }

        request_payload = {
            "model": "gpt-4.1-mini",
            "instructions": system_instructions,
            "input": [{"role": "user", "content": query_text}],
            "tools": [
                {
                    "type": "file_search",
                    "vector_store_ids": [vector_store_id],
                    "max_num_results": 10,
                    "ranking_options": {"score_threshold": 0.2},
                    "filters": {"key": "room_number", "type": "eq", "value": "201"} # TODO: 動的に設定
                }
            ],
            "tool_choice": "required",
            "temperature": 0.0,
            "text": {
                "format": {
                    "type": "json_schema",
                    "name": "AssistantResponseWithOperatorFlag",
                    "schema": response_format_schema,
                    "strict": True
                }
            }
        }
        if previous_response_id: # ★ 条件を有効化
            request_payload["previous_response_id"] = previous_response_id

        response = await openai_async_client.responses.create(**request_payload)

        print("--- OpenAI API Response (Success with JSON Schema) ---")
        # print(response) # デバッグ用にレスポンス全体を出力しても良い
        current_response_id = None
        if response and hasattr(response, 'id'):
            current_response_id = response.id
            print(f"Response ID: {current_response_id}")
        else:
            print("Warning: Could not retrieve response ID from API response.")
        print("--- End of OpenAI API Response ---")

        final_json_output = {
            "assistant_response_text": "検索結果に基づく応答の抽出に失敗しました。",
            "needs_operator": False,
            "response_id": current_response_id
        }

        if response and hasattr(response, 'output'):
            if isinstance(response.output, list) and len(response.output) > 0:
                output_message_item = next((item for item in reversed(response.output) if hasattr(item, 'type') and item.type == 'message'), None)
                
                if output_message_item and hasattr(output_message_item, 'content') and \
                   isinstance(output_message_item.content, list) and len(output_message_item.content) > 0:
                    
                    output_text_obj = output_message_item.content[0]
                    if hasattr(output_text_obj, 'type') and output_text_obj.type == 'output_text':
                        # モデルが生成したテキスト部分の処理
                        if hasattr(output_text_obj, 'text') and isinstance(output_text_obj.text, str):
                            try:
                                model_generated_data = json.loads(output_text_obj.text)
                                final_json_output["assistant_response_text"] = model_generated_data.get("assistant_response_text", "Error: 'assistant_response_text' key missing.")
                                final_json_output["needs_operator"] = model_generated_data.get("needs_operator", False)
                            except json.JSONDecodeError:
                                print(f"Error: Failed to parse JSON from model output: {output_text_obj.text}")
                    else:
                        print(f"Error: Expected ResponseOutputText, but got: {output_text_obj}")
                else:
                    print("Error: Could not find valid ResponseOutputMessage content.")
            else:
                print(f"Error: response.output is not a list or is empty: {response.output}")
        else:
            print("Error: Response object or response.output is missing.")

        generated_json_string = json.dumps(final_json_output, ensure_ascii=False)
        print(f"File Search Tool による応答生成完了。最終JSON文字列: {generated_json_string}")
        return generated_json_string

    except openai.APIConnectionError as e:
        print(f"OpenAI APIへの接続エラー: {e}")
        # "retrieved_annotations" を削除
        return json.dumps({"assistant_response_text": "申し訳ありません、現在データベースへの接続に問題が発生しています。", "needs_operator": False, "response_id": None}, ensure_ascii=False)
    except openai.RateLimitError as e:
        print(f"OpenAI APIレート制限エラー: {e}")
        # "retrieved_annotations" を削除
        return json.dumps({"assistant_response_text": "現在、多くのお問い合わせを処理中です。恐れ入りますが、少し時間をおいて再度お試しください。", "needs_operator": False, "response_id": None}, ensure_ascii=False)
    except openai.APIStatusError as e:
        error_details_str = "N/A"
        try:
            error_details_json = e.response.json()
            error_details_str = json.dumps(error_details_json, indent=2, ensure_ascii=False)
        except json.JSONDecodeError:
            error_details_str = e.response.text
        except Exception as ex_detail:
            error_details_str = f"エラー詳細の取得中に別のエラーが発生: {ex_detail}"
        print(f"OpenAI APIステータスエラー (HTTP {e.status_code}): {e.response}")
        print(f"エラー詳細:\n{error_details_str}")
        # "retrieved_annotations" を削除
        return json.dumps({"assistant_response_text": "データベース検索中に予期せぬエラーが発生しました。管理者にご連絡ください。", "needs_operator": False, "response_id": None}, ensure_ascii=False)
    except Exception as e:
        print(f"File Search Tool 処理中に予期せぬエラーが発生しました: {e}")
        # "retrieved_annotations" を削除
        return json.dumps({"assistant_response_text": f"「{query_text}」の検索中にエラーが発生しました。", "needs_operator": False, "response_id": None}, ensure_ascii=False)

# # --- テスト実行用のコード ---
# if __name__ == "__main__":
#     import asyncio
#     import os
#     from dotenv import load_dotenv

#     load_dotenv()

#     async def main_file_search_test():
#         api_key = os.environ.get("OPENAI_API_KEY")
#         if not api_key:
#             print("テスト実行エラー: 環境変数 OPENAI_API_KEY が設定されていません。")
#             return
        
#         test_vector_store_id = os.environ.get("TEST_VECTOR_STORE_ID", "")
#         if not test_vector_store_id:
#              print(f"警告: テスト用のベクトルストアID (TEST_VECTOR_STORE_ID) が設定されていません。")

#         openai_async_client = openai.AsyncOpenAI(api_key=api_key)

#         print("\n--- File Search Tool (Responses APIスタイル) テスト開始 ---")
#         # ... (test_queries の定義) ...
#         test_queries = {
#             "部屋のキーの場所": "部屋のキーはどこですか？",
#             # "プールの情報": "プールは使えますか？",
#             # "ホテルまでの道のり": "ホテルまでの行き方を教えてください。",
#         }
#         for description, query in test_queries.items():
#             print(f"\nテストクエリ ({description}): 「{query}」")
#             result = await openai_vector_search_with_file_search_tool(
#                 openai_async_client,
#                 query,
#                 "日本語",
#                 test_vector_store_id
#             )
#             print(f"検索結果/応答: {result}")
#             # 必要であれば、ここで result (JSON文字列) をパースして内容を確認
#             try:
#                 data = json.loads(result)
#                 print(f"  -> パース後 - テキスト: {data.get('assistant_response_text')}")
#                 print(f"  -> パース後 - オペレーター要否: {data.get('needs_operator')}")
#                 print(f"  -> パース後 - 応答ID: {data.get('response_id')}")
#             except json.JSONDecodeError:
#                 print("  -> エラー: 返されたJSON文字列のパースに失敗しました。")
        
#         print("\n--- File Search Tool テスト終了 ---")
#         await openai_async_client.close()

#     asyncio.run(main_file_search_test())